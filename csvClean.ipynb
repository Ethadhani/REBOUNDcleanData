{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Falsely Labeled systems and duplicated systems from dataset\n",
    "\n",
    "This process removes systems that were falsely labeled as stable, when in fact, one or more body in the system had been ejected and thus no collisions occured.\n",
    "Additionally, this process removes duplicated systems from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used pre labeled datasheets which have identified which systems have ejections. The process for determining if a system has an ejection and creating these datasheets can be found in findEjections.ipynb. To briefly summarize, we re load the final snapshot after integration of each system, we are then able to check if a body has been ejected from the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomejections = pd.read_csv('randomejections.csv')\n",
    "resonantejections = pd.read_csv('resonantejections.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we manually specify the names of the datasheet columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels for columns of Initial conditions and labels\n",
    "col = ['p0m','p0x','p0y','p0z','p0vx','p0vy','p0vz','p1m','p1x','p1y','p1z','p1vx','p1vy','p1vz','p2m','p2x','p2y','p2z','p2vx','p2vy','p2vz','p3m','p3x','p3y','p3z','p3vx','p3vy','p3vz']\n",
    "lab = ['runstring', 'instability_time',\n",
    "       'shadow_instability_time', 'Stable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are then able to load the initial conditions and labels for the random and resonant systems, joining the datasheets to ensure that a system and its corresponding labels stay together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load path and data for random datasets\n",
    "randomPath = 'csvs/random/'\n",
    "randomInitial = pd.read_csv(randomPath+'initial_conditions.csv',header=None)\n",
    "randomLabels = pd.read_csv(randomPath+'labels.csv')\n",
    "randomInitial.columns = col #adds labels to initial condition columns\n",
    "randset = pd.DataFrame.join(randomInitial, randomLabels) #joins initial conditions and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load path and data for resonant datasets\n",
    "resPath = 'csvs/resonant/'\n",
    "resInitial = pd.read_csv(resPath+'initial_conditions.csv',header=None)\n",
    "resLabels = pd.read_csv(resPath+'labels.csv')\n",
    "resInitial.columns = col #adds labels to initial condition columns\n",
    "resset = pd.DataFrame.join(resInitial, resLabels) #joins initial conditions and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then merge these datasheets with the ejection data, matching the systems to the proper label by looking at the unique runstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combines dataset with ejection data based on runstring\n",
    "randset = pd.merge(randset,randomejections[['runstring','ejection']],on='runstring')\n",
    "resset = pd.merge(resset,resonantejections[['runstring','ejection']],on='runstring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes junk columns\n",
    "randset = randset.drop('Unnamed: 0',axis=1)\n",
    "resset = resset.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are then able to get a sense of how many systems either are ejected, or are duplicates of another system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random:\n",
      "ejection\n",
      "False    24941\n",
      "True        59\n",
      "Name: count, dtype: int64\n",
      "resonant:\n",
      "ejection\n",
      "False    113478\n",
      "True         65\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking how many ejection systems exist\n",
    "print('random:')\n",
    "print(randset['ejection'].value_counts())\n",
    "print('resonant:')\n",
    "print(resset['ejection'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds duplicates and lables them, this will label all duplicates, other than the first appearance\n",
    "randset['isDup']=randset[col].duplicated()\n",
    "resset['isDup']=resset[col].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random:\n",
      "isDup\n",
      "False    25000\n",
      "Name: count, dtype: int64\n",
      "resonant:\n",
      "isDup\n",
      "False    102559\n",
      "True      10984\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking how many duplicated systems in each dataset, this process labels the first instance of any system as False, \n",
    "# and lables any duplicates after the first instance as True\n",
    "print('random:')\n",
    "print(randset['isDup'].value_counts()) #the duplicated systems have the same initial conditions\n",
    "print('resonant:')\n",
    "print(resset['isDup'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a new column specifying whether each row should be removed from the data set or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labeling each row as to whether or not it should be removed\n",
    "randset['remove']=(randset['ejection']==True) | (randset['isDup']==True)\n",
    "resset['remove']=(resset['ejection']==True) | (resset['isDup']==True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total we will need to remove 59 systems from the random data, and 11046 systems from the resonant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random:\n",
      "remove\n",
      "False    24941\n",
      "True        59\n",
      "Name: count, dtype: int64\n",
      "resonant:\n",
      "remove\n",
      "False    102497\n",
      "True      11046\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#determining how many total systems need to be dropped\n",
    "print('random:')\n",
    "print(randset['remove'].value_counts())\n",
    "print('resonant:')\n",
    "print(resset['remove'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the label list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resset[['runstring','remove']].to_csv(resPath+'removeLables.csv')\n",
    "randset[['runstring','remove']].to_csv(randomPath+'removeLables.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes the bad samples\n",
    "randset = randset.drop(randset[randset['remove']==True].index)\n",
    "resset = resset.drop(resset[resset['remove']==True].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then separate the datasheets in the same format as the original data, and save the new clean csvs in the same file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperates lables from initial conditions\n",
    "cleanrandinitial = randset[col+['runstring']]\n",
    "cleanrandlables = randset[lab]\n",
    "cleanresinitial = resset[col+['runstring']]\n",
    "cleanreslables = resset[lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves clean data\n",
    "cleanrandinitial.to_csv(randomPath+'clean_initial_conditions.csv')\n",
    "cleanrandlables.to_csv(randomPath+'clean_labels.csv')\n",
    "cleanresinitial.to_csv(resPath+'clean_initial_conditions.csv')\n",
    "cleanreslables.to_csv(resPath+'clean_labels.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are then left with a clean data set that should no longer have falsely labeled systems or duplicate systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethadhani",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
